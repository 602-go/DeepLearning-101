{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/changsin/DeepLearning-101/blob/master/02-tf-train-basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9,)\n"
     ]
    }
   ],
   "source": [
    "# X and Y data\n",
    "x_train = np.array([-1, 0, 1, 2, 3, 4, 5, 6, 7]).astype('float32')\n",
    "y_train = np.array([-2, 0, 2, 4, 6, 8, 10, 12, 14]).astype('float32')\n",
    "\n",
    "# Try to find values for W and b to compute y_data = x_data * W + b\n",
    "# We know that W should be 1 and b should be 0\n",
    "# But let TensorFlow figure it out\n",
    "W = tf.Variable(tf.random.normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random.normal([1]), name=\"bias\")\n",
    "\n",
    "# Our hypothes is XW+b\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "# cost/loss function\n",
    "def loss_function(hypothesis, y_train):\n",
    "    return tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "# optimizer\n",
    "train_optimizer = keras.optimizers.SGD(learning_rate=0.073)\n",
    "print(np.array(x_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 3)                 6         \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(units=1, input_shape=[1], name=\"layer1\"),\n",
    "    keras.layers.Dense(3, activation=\"sigmoid\", name=\"layer2\"),\n",
    "    keras.layers.Dense(1, name=\"layer3\"),\n",
    "])\n",
    "\n",
    "y = model(x_train, y_train)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=train_optimizer,\n",
    "              loss=loss_function,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_acc = model.evaluate(x_train, y_train, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1111111119389534\n",
      "[[ 1.2986152]\n",
      " [ 4.32703  ]\n",
      " [ 8.133838 ]\n",
      " [12.11902  ]]\n"
     ]
    }
   ],
   "source": [
    "print(train_acc)\n",
    "\n",
    "print(model.predict([1, 2, 3, 6]))\n",
    "# print(model.predict([7, 8, 9]))\n",
    "# print(model.predict([10, 12, 13]))\n",
    "\n",
    "# print(model.predict([100, 120, 130]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'weight:0' shape=(1,) dtype=float32, numpy=array([0.9613515], dtype=float32)>\n",
      "<tf.Variable 'bias:0' shape=(1,) dtype=float32, numpy=array([-0.79824007], dtype=float32)>\n",
      "tf.Tensor(\n",
      "[-1.7595916  -0.79824007  0.16311145  1.124463    2.0858145   3.0471659\n",
      "  4.0085173   4.969869    5.9312205 ], shape=(9,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(W)\n",
    "print(b)\n",
    "print(hypothesis)\n",
    "\n",
    "loss = lambda: var_num\n",
    "\n",
    "# loss_fn = lambda: tf.keras.losses.mse(model(x_train), output)\n",
    "# var_list_fn = lambda: model.trainable_weights\n",
    "\n",
    "var_num = tf.Variable(10.0)\n",
    "train_optimizer.minimize(loss, [var_num]).numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
